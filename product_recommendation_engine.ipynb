{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMjracM0Z2Te"
      },
      "outputs": [],
      "source": [
        "# ========== PRODUCT RECOMMENDATION ENGINE - GOOGLE COLAB ==========\n",
        "# üîó Click \"Copy to Drive\" to save your own copy\n",
        "\n",
        "# ==================== SETUP ====================\n",
        "!pip install scikit-learn surprise tensorflow\n",
        "!pip install pandas numpy matplotlib seaborn\n",
        "!pip install fastapi uvicorn -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive, files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==================== RECOMMENDATION SYSTEM ====================\n",
        "class RecommendationEngine:\n",
        "    \"\"\"Hybrid recommendation engine with multiple algorithms\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.user_item_matrix = None\n",
        "        self.item_similarity = None\n",
        "        self.user_similarity = None\n",
        "        self.rf_model = None\n",
        "        self.neural_model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.metrics = {}\n",
        "\n",
        "    def generate_sample_data(self, n_users=1000, n_items=500, n_interactions=50000):\n",
        "        \"\"\"Generate sample e-commerce data\"\"\"\n",
        "        print(\"üîÑ Generating sample e-commerce data...\")\n",
        "\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Users data\n",
        "        users = pd.DataFrame({\n",
        "            'user_id': range(1, n_users + 1),\n",
        "            'age': np.random.randint(18, 70, n_users),\n",
        "            'gender': np.random.choice(['M', 'F'], n_users),\n",
        "            'location': np.random.choice(['Urban', 'Suburban', 'Rural'], n_users),\n",
        "            'income': np.random.uniform(30000, 150000, n_users)\n",
        "        })\n",
        "\n",
        "        # Items data\n",
        "        categories = ['Electronics', 'Clothing', 'Books', 'Home', 'Sports', 'Beauty']\n",
        "        items = pd.DataFrame({\n",
        "            'item_id': range(1, n_items + 1),\n",
        "            'category': np.random.choice(categories, n_items),\n",
        "            'price': np.random.uniform(10, 500, n_items),\n",
        "            'rating': np.random.uniform(3.0, 5.0, n_items),\n",
        "            'popularity': np.random.randint(1, 100, n_items)\n",
        "        })\n",
        "\n",
        "        # Interactions data\n",
        "        interactions = []\n",
        "        for _ in range(n_interactions):\n",
        "            user_id = np.random.randint(1, n_users + 1)\n",
        "            item_id = np.random.randint(1, n_items + 1)\n",
        "            rating = np.random.choice([1, 2, 3, 4, 5], p=[0.05, 0.1, 0.3, 0.4, 0.15])\n",
        "            timestamp = pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 365))\n",
        "\n",
        "            interactions.append({\n",
        "                'user_id': user_id,\n",
        "                'item_id': item_id,\n",
        "                'rating': rating,\n",
        "                'timestamp': timestamp\n",
        "            })\n",
        "\n",
        "        interactions_df = pd.DataFrame(interactions)\n",
        "\n",
        "        # Remove duplicates\n",
        "        interactions_df = interactions_df.drop_duplicates(subset=['user_id', 'item_id'])\n",
        "\n",
        "        print(f\"‚úÖ Generated data:\")\n",
        "        print(f\"   ‚Ä¢ {len(users)} users\")\n",
        "        print(f\"   ‚Ä¢ {len(items)} items\") = np.random.choice(df.index, size=int(n_rows * 0.1), replace=False)\n",
        "        for idx in null_indices:\n",
        "            col = np.random.choice(['name', 'email', 'age', 'salary'])\n",
        "            df.loc[idx, col] = None\n",
        "\n",
        "        # 3. Invalid email format (5%)\n",
        "        invalid_email_indices = np.random.choice(df.index, size=int(n_rows * 0.05), replace=False)\n",
        "        df.loc[invalid_email_indices, 'email'] = 'invalid_email_format'\n",
        "\n",
        "        # 4. Outliers in salary (3%)\n",
        "        outlier_indices = np.random.choice(df.index, size=int(n_rows * 0.03), replace=False)\n",
        "        df.loc[outlier_indices, 'salary'] = np.random.uniform(1000000, 5000000, len(outlier_indices))\n",
        "\n",
        "        # 5. Negative ages (2%)\n",
        "        neg_age_indices = np.random.choice(df.index, size=int(n_rows * 0.02), replace=False)\n",
        "        df.loc[neg_age_indices, 'age'] = np.random.randint(-10, 0, len(neg_age_indices))\n",
        "\n",
        "        # 6. Inconsistent product categories (5%)\n",
        "        inconsistent_indices = np.random.choice(df.index, size=int(n_rows * 0.05), replace=False)\n",
        "        df.loc[inconsistent_indices, 'product_category'] = np.random.choice(['XYZ', 'ABC', '123'], len(inconsistent_indices))\n",
        "\n",
        "        # Shuffle the data\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(df)} rows with intentional quality issues\")\n",
        "        return df\n",
        "\n",
        "    def check_completeness(self, df):\n",
        "        \"\"\"Check for missing values\"\"\"\n",
        "        print(\"üîç Checking data completeness...\")\n",
        "\n",
        "        missing_data = df.isnull().sum()\n",
        "        missing_percentage = (missing_data / len(df)) * 100\n",
        "\n",
        "        completeness_report = pd.DataFrame({\n",
        "            'Column': df.columns,\n",
        "            'Missing_Count': missing_data.values,\n",
        "            'Missing_Percentage': missing_percentage.values\n",
        "        })\n",
        "\n",
        "        print(\"Missing Data Summary:\")\n",
        "        print(completeness_report)\n",
        "\n",
        "        # Flag columns with >5% missing data\n",
        "        high_missing = completeness_report[completeness_report['Missing_Percentage'] > 5]\n",
        "        if not high_missing.empty:\n",
        "            self.issues_found.extend([\n",
        "                f\"High missing data in {row['Column']}: {row['Missing_Percentage']:.1f}%\"\n",
        "                for _, row in high_missing.iterrows()\n",
        "            ])\n",
        "            self.rules_failed += len(high_missing)\n",
        "        else:\n",
        "            self.rules_passed += len(df.columns)\n",
        "\n",
        "        return completeness_report\n",
        "\n",
        "    def check_uniqueness(self, df):\n",
        "        \"\"\"Check for duplicate records\"\"\"\n",
        "        print(\"üîç Checking data uniqueness...\")\n",
        "\n",
        "        duplicate_count = df.duplicated().sum()\n",
        "        duplicate_percentage = (duplicate_count / len(df)) * 100\n",
        "\n",
        "        print(f\"Duplicate rows found: {duplicate_count} ({duplicate_percentage:.2f}%)\")\n",
        "\n",
        "        if duplicate_count > 0:\n",
        "            self.issues_found.append(f\"Duplicate rows: {duplicate_count} ({duplicate_percentage:.2f}%)\")\n",
        "            self.rules_failed += 1\n",
        "        else:\n",
        "            self.rules_passed += 1\n",
        "\n",
        "        return duplicate_count, duplicate_percentage\n",
        "\n",
        "    def check_validity(self, df):\n",
        "        \"\"\"Check data validity and format\"\"\"\n",
        "        print(\"üîç Checking data validity...\")\n",
        "\n",
        "        validity_issues = []\n",
        "\n",
        "        # Check email format\n",
        "        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
        "        invalid_emails = ~df['email'].str.match(email_pattern, na=False)\n",
        "        invalid_email_count = invalid_emails.sum()\n",
        "\n",
        "        if invalid_email_count > 0:\n",
        "            validity_issues.append(f\"Invalid email format: {invalid_email_count}\")\n",
        "\n",
        "        # Check age validity\n",
        "        invalid_ages = (df['age'] < 0) | (df['age'] > 120)\n",
        "        invalid_age_count = invalid_ages.sum()\n",
        "\n",
        "        if invalid_age_count > 0:\n",
        "            validity_issues.append(f\"Invalid ages: {invalid_age_count}\")\n",
        "\n",
        "        # Check salary validity\n",
        "        invalid_salaries = (df['salary'] < 0) | (df['salary'] > 10000000)\n",
        "        invalid_salary_count = invalid_salaries.sum()\n",
        "\n",
        "        if invalid_salary_count > 0:\n",
        "            validity_issues.append(f\"Invalid salaries: {invalid_salary_count}\")\n",
        "\n",
        "        # Check categorical values\n",
        "        valid_categories = ['Electronics', 'Clothing', 'Books', 'Home']\n",
        "        invalid_categories = ~df['product_category'].isin(valid_categories)\n",
        "        invalid_category_count = invalid_categories.sum()\n",
        "\n",
        "        if invalid_category_count > 0:\n",
        "            validity_issues.append(f\"Invalid product categories: {invalid_category_count}\")\n",
        "\n",
        "        if validity_issues:\n",
        "            self.issues_found.extend(validity_issues)\n",
        "            self.rules_failed += len(validity_issues)\n",
        "        else:\n",
        "            self.rules_passed += 4\n",
        "\n",
        "        return validity_issues\n",
        "\n",
        "    def check_consistency(self, df):\n",
        "        \"\"\"Check data consistency\"\"\"\n",
        "        print(\"üîç Checking data consistency...\")\n",
        "\n",
        "        consistency_issues = []\n",
        "\n",
        "        # Check for logical inconsistencies\n",
        "        # Age vs salary consistency (young people with very high salaries)\n",
        "        young_high_salary = df[(df['age'] < 25) & (df['salary'] > 200000)]\n",
        "        if len(young_high_salary) > 0:\n",
        "            consistency_issues.append(f\"Young people with high salaries: {len(young_high_salary)}\")\n",
        "\n",
        "        # Purchase amount vs quantity consistency\n",
        "        high_amount_low_quantity = df[(df['purchase_amount'] > 500) & (df['quantity'] == 1)]\n",
        "        if len(high_amount_low_quantity) > len(df) * 0.1:\n",
        "            consistency_issues.append(f\"High amount purchases with single quantity: {len(high_amount_low_quantity)}\")\n",
        "\n",
        "        if consistency_issues:\n",
        "            self.issues_found.extend(consistency_issues)\n",
        "            self.rules_failed += len(consistency_issues)\n",
        "        else:\n",
        "            self.rules_passed += 2\n",
        "\n",
        "        return consistency_issues\n",
        "\n",
        "    def detect_outliers(self, df):\n",
        "        \"\"\"Detect outliers using statistical methods\"\"\"\n",
        "        print(\"üîç Detecting outliers...\")\n",
        "\n",
        "        outlier_report = {}\n",
        "\n",
        "        # Numerical columns to check\n",
        "        numerical_cols = ['age', 'salary', 'purchase_amount', 'quantity']\n",
        "\n",
        "        for col in numerical_cols:\n",
        "            if col in df.columns:\n",
        "                # IQR method\n",
        "                Q1 = df[col].quantile(0.25)\n",
        "                Q3 = df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "                outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "                outlier_count = len(outliers)\n",
        "\n",
        "                if outlier_count > 0:\n",
        "                    outlier_report[col] = {\n",
        "                        'count': outlier_count,\n",
        "                        'percentage': (outlier_count / len(df)) * 100,\n",
        "                        'lower_bound': lower_bound,\n",
        "                        'upper_bound': upper_bound\n",
        "                    }\n",
        "\n",
        "        if outlier_report:\n",
        "            self.issues_found.extend([\n",
        "                f\"Outliers in {col}: {info['count']} ({info['percentage']:.2f}%)\"\n",
        "                for col, info in outlier_report.items()\n",
        "            ])\n",
        "            self.rules_failed += len(outlier_report)\n",
        "        else:\n",
        "            self.rules_passed += len(numerical_cols)\n",
        "\n",
        "        return outlier_report\n",
        "\n",
        "    def calculate_quality_score(self):\n",
        "        \"\"\"Calculate overall data quality score\"\"\"\n",
        "        total_rules = self.rules"
      ]
    }
  ]
}